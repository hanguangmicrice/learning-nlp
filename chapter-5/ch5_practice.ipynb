{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import jieba\n",
    "import jieba.posseg as psg\n",
    "from gensim import corpora, models\n",
    "from jieba import analyse\n",
    "import functools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopword_list():\n",
    "    stop_word_path = './stopword.txt'\n",
    "    stopwords_list = [sw.replace('\\n','') for sw in open(stop_word_path).readlines()]\n",
    "    return stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_to_list(sentence, pos=False):\n",
    "    if not pos:\n",
    "        return jieba.cut(sentence)\n",
    "    else:\n",
    "        return psg.cut(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(seg_list, pos=False):\n",
    "    stopwords = get_stopword_list()\n",
    "    filter_list = []\n",
    "    for seg in seg_list:\n",
    "        if not pos:\n",
    "            word = seg \n",
    "            flag = 'n'\n",
    "        else:\n",
    "            word = seg.word\n",
    "            flag = seg.flag\n",
    "        if not flag.startwith('n'):\n",
    "            continue\n",
    "        if word not in stopwords and len(word)>1:\n",
    "            filter_list.append(word)\n",
    "    return filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(pos=False, corpus_path='./corpus.txt'):\n",
    "    doc_list = []\n",
    "    for line in open(corpus_path):\n",
    "        content = line.strip()\n",
    "        seg_list = seg_to_list(content,pos)\n",
    "        filter_list = word_filter(seg_list,pos)\n",
    "        doc_list.append(filter_list)\n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_idf(doc_list):\n",
    "    idf_dic={}\n",
    "    tt_count = len(doc_list)\n",
    "    \n",
    "    #每个词出现的文档数\n",
    "    for i in doc_list:\n",
    "        for j in set(i):\n",
    "            idf_dic[j] = idf_dic.get(j,0)+1\n",
    "    #calculate the idf\n",
    "    for k,v in idf_dic.items():\n",
    "        idf_dic[k] = math.log(tt_count/(1+v))\n",
    "    #for oov use default value\n",
    "    default_idf = math.log(tt_count)\n",
    "    return idf_dic, default_idf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(e1, e2):\n",
    "    res = np.sign(e1[1]-e2[1])\n",
    "    if res != 0:\n",
    "        return res\n",
    "    else:\n",
    "        a = e1[0] + e2[0]\n",
    "        b = e2[0] + e1[0]\n",
    "        if a>b:\n",
    "            return 1\n",
    "        elif a==b:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdf(object):\n",
    "    def __init__(self,idf_dic, default_idf,word_list, keyword_num):\n",
    "        self.word_list = word_list\n",
    "        self.idf_dic, self.default_idf= idf_dic, default_idf\n",
    "        self.tf_dict = self.get_tf_dic()\n",
    "        self.keyword_num = keyword_num\n",
    "    def get_tf_dic(self):\n",
    "        tf_dict = {}\n",
    "        for i in self.word_list:\n",
    "            tf_dict[i]  = tf_dict.get(i, 0)+1\n",
    "        tt_count = len(self.word_list)\n",
    "        for k, v in word_list.items():\n",
    "            tf_dict[k] = v/tt_count\n",
    "        return tf_dict\n",
    "    def get_tfidf(self):\n",
    "        tfidf_dict={}\n",
    "        for word in self.word_list:\n",
    "            tf = self.tf_dict.get(word,0)\n",
    "            idf = self.idf_dic.get(word, self.default_idf)\n",
    "            tfidf_dict[word] = tf*idf\n",
    "        for k, v in sorted(tfidf_dic.items(), key=functools.cmp_to_key(cmp), reverse=True)[:self.keyword_num]:\n",
    "            print(k + \"/ \", end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('cv': conda)",
   "language": "python",
   "name": "python37564bitcvconda3c0e0165231c451c8353e446d79e7e9a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
